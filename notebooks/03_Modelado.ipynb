{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6521e2c2",
   "metadata": {},
   "source": [
    "# 03_Modelado ‚Äî Comparaci√≥n de clasificadores (regresi√≥n log√≠stica, √°rbol y random forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e23b5e4",
   "metadata": {},
   "source": [
    "# Importaci√≥n de librer√≠as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eaee935c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline as SKPipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import (\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    classification_report,\n",
    "    confusion_matrix\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6b813f",
   "metadata": {},
   "source": [
    "# Lectura del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "153022d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>education_level</th>\n",
       "      <th>income_level</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>alcohol_consumption_per_week</th>\n",
       "      <th>physical_activity_minutes_per_week</th>\n",
       "      <th>diet_score</th>\n",
       "      <th>...</th>\n",
       "      <th>hdl_cholesterol</th>\n",
       "      <th>ldl_cholesterol</th>\n",
       "      <th>triglycerides</th>\n",
       "      <th>glucose_fasting</th>\n",
       "      <th>glucose_postprandial</th>\n",
       "      <th>insulin_level</th>\n",
       "      <th>hba1c</th>\n",
       "      <th>diabetes_risk_score</th>\n",
       "      <th>diabetes_stage</th>\n",
       "      <th>diagnosed_diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>Male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Highschool</td>\n",
       "      <td>Lower-Middle</td>\n",
       "      <td>Employed</td>\n",
       "      <td>Never</td>\n",
       "      <td>0</td>\n",
       "      <td>215</td>\n",
       "      <td>5.7</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>160</td>\n",
       "      <td>145</td>\n",
       "      <td>136</td>\n",
       "      <td>236</td>\n",
       "      <td>6.36</td>\n",
       "      <td>8.18</td>\n",
       "      <td>29.6</td>\n",
       "      <td>Type 2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>Highschool</td>\n",
       "      <td>Middle</td>\n",
       "      <td>Employed</td>\n",
       "      <td>Former</td>\n",
       "      <td>1</td>\n",
       "      <td>143</td>\n",
       "      <td>6.7</td>\n",
       "      <td>...</td>\n",
       "      <td>55</td>\n",
       "      <td>50</td>\n",
       "      <td>30</td>\n",
       "      <td>93</td>\n",
       "      <td>150</td>\n",
       "      <td>2.00</td>\n",
       "      <td>5.63</td>\n",
       "      <td>23.0</td>\n",
       "      <td>No Diabetes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>Highschool</td>\n",
       "      <td>Middle</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>Never</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>6.4</td>\n",
       "      <td>...</td>\n",
       "      <td>66</td>\n",
       "      <td>99</td>\n",
       "      <td>36</td>\n",
       "      <td>118</td>\n",
       "      <td>195</td>\n",
       "      <td>5.07</td>\n",
       "      <td>7.51</td>\n",
       "      <td>44.7</td>\n",
       "      <td>Type 2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74</td>\n",
       "      <td>Female</td>\n",
       "      <td>Black</td>\n",
       "      <td>Highschool</td>\n",
       "      <td>Low</td>\n",
       "      <td>Retired</td>\n",
       "      <td>Never</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>3.4</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>79</td>\n",
       "      <td>140</td>\n",
       "      <td>139</td>\n",
       "      <td>253</td>\n",
       "      <td>5.28</td>\n",
       "      <td>9.03</td>\n",
       "      <td>38.2</td>\n",
       "      <td>Type 2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Middle</td>\n",
       "      <td>Retired</td>\n",
       "      <td>Never</td>\n",
       "      <td>1</td>\n",
       "      <td>109</td>\n",
       "      <td>7.2</td>\n",
       "      <td>...</td>\n",
       "      <td>52</td>\n",
       "      <td>125</td>\n",
       "      <td>160</td>\n",
       "      <td>137</td>\n",
       "      <td>184</td>\n",
       "      <td>12.74</td>\n",
       "      <td>7.20</td>\n",
       "      <td>23.5</td>\n",
       "      <td>Type 2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  gender ethnicity education_level  income_level employment_status  \\\n",
       "0   58    Male     Asian      Highschool  Lower-Middle          Employed   \n",
       "1   48  Female     White      Highschool        Middle          Employed   \n",
       "2   60    Male  Hispanic      Highschool        Middle        Unemployed   \n",
       "3   74  Female     Black      Highschool           Low           Retired   \n",
       "4   46    Male     White        Graduate        Middle           Retired   \n",
       "\n",
       "  smoking_status  alcohol_consumption_per_week  \\\n",
       "0          Never                             0   \n",
       "1         Former                             1   \n",
       "2          Never                             1   \n",
       "3          Never                             0   \n",
       "4          Never                             1   \n",
       "\n",
       "   physical_activity_minutes_per_week  diet_score  ...  hdl_cholesterol  \\\n",
       "0                                 215         5.7  ...               41   \n",
       "1                                 143         6.7  ...               55   \n",
       "2                                  57         6.4  ...               66   \n",
       "3                                  49         3.4  ...               50   \n",
       "4                                 109         7.2  ...               52   \n",
       "\n",
       "   ldl_cholesterol  triglycerides  glucose_fasting  glucose_postprandial  \\\n",
       "0              160            145              136                   236   \n",
       "1               50             30               93                   150   \n",
       "2               99             36              118                   195   \n",
       "3               79            140              139                   253   \n",
       "4              125            160              137                   184   \n",
       "\n",
       "   insulin_level  hba1c  diabetes_risk_score  diabetes_stage  \\\n",
       "0           6.36   8.18                 29.6          Type 2   \n",
       "1           2.00   5.63                 23.0     No Diabetes   \n",
       "2           5.07   7.51                 44.7          Type 2   \n",
       "3           5.28   9.03                 38.2          Type 2   \n",
       "4          12.74   7.20                 23.5          Type 2   \n",
       "\n",
       "   diagnosed_diabetes  \n",
       "0                   1  \n",
       "1                   0  \n",
       "2                   1  \n",
       "3                   1  \n",
       "4                   1  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/diabetes_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aaf825c",
   "metadata": {},
   "source": [
    "# Depuraci√≥n de variables y definici√≥n de X y Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40619bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape de X: (100000, 27)\n",
      "Distribuci√≥n de y:\n",
      "diagnosed_diabetes\n",
      "1    0.59998\n",
      "0    0.40002\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "cols_to_drop = ['diabetes_stage', 'cholesterol_total', 'glucose_postprandial']\n",
    "df = df.drop(columns=cols_to_drop, errors='ignore')\n",
    "\n",
    "target_col = 'diagnosed_diabetes'\n",
    "\n",
    "if target_col not in df.columns:\n",
    "    raise ValueError(f\"La columna objetivo '{target_col}' no existe en el dataframe.\")\n",
    "\n",
    "X = df.drop(columns=[target_col])\n",
    "y = df[target_col].copy()\n",
    "\n",
    "print(\"Shape de X:\", X.shape)\n",
    "print(\"Distribuci√≥n de y:\")\n",
    "print(y.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cdc5ef",
   "metadata": {},
   "source": [
    "# Divisi√≥n en train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ab70c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (80000, 27) X_test: (20000, 27)\n",
      "\n",
      "Proporci√≥n en train:\n",
      "diagnosed_diabetes\n",
      "1    0.599975\n",
      "0    0.400025\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Proporci√≥n en test:\n",
      "diagnosed_diabetes\n",
      "1    0.6\n",
      "0    0.4\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"X_train:\", X_train.shape, \"X_test:\", X_test.shape)\n",
    "print(\"\\nProporci√≥n en train:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(\"\\nProporci√≥n en test:\")\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5854f09",
   "metadata": {},
   "source": [
    "# Identificaci√≥n de tipos de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9926d93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num√©ricas a escalar: ['age', 'alcohol_consumption_per_week', 'physical_activity_minutes_per_week', 'diet_score', 'sleep_hours_per_day', 'screen_time_hours_per_day', 'bmi', 'waist_to_hip_ratio', 'systolic_bp', 'diastolic_bp', 'heart_rate', 'hdl_cholesterol', 'ldl_cholesterol', 'triglycerides', 'glucose_fasting', 'insulin_level', 'hba1c', 'diabetes_risk_score']\n",
      "Binarias (sin escalar): ['family_history_diabetes', 'hypertension_history', 'cardiovascular_history']\n",
      "Categ√≥ricas: ['gender', 'ethnicity', 'education_level', 'income_level', 'employment_status', 'smoking_status']\n"
     ]
    }
   ],
   "source": [
    "num_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = X_train.select_dtypes(include=['object', 'category', 'bool']).columns.tolist()\n",
    "\n",
    "binary_cols = ['family_history_diabetes', 'hypertension_history', 'cardiovascular_history']\n",
    "\n",
    "numeric_to_scale = [col for col in num_cols if col not in binary_cols]\n",
    "\n",
    "print(\"Num√©ricas a escalar:\", numeric_to_scale)\n",
    "print(\"Binarias (sin escalar):\", binary_cols)\n",
    "print(\"Categ√≥ricas:\", cat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55904057",
   "metadata": {},
   "source": [
    "# Transformaciones: escalado y one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45091b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = SKPipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = SKPipeline(steps=[\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num_scaled', numeric_transformer, numeric_to_scale),\n",
    "    ('num_binary', 'passthrough', binary_cols),\n",
    "    ('cat', categorical_transformer, cat_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cda588a",
   "metadata": {},
   "source": [
    "# Definici√≥n de modelos base con balanceo (regresi√≥n log√≠stica, √°rbol y random forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a54da01",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_clf = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(\n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf_clf = RandomForestClassifier(\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c0b7fd",
   "metadata": {},
   "source": [
    "# Construcci√≥n de pipelines por modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50e6441b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_logreg = SKPipeline(steps=[\n",
    "    ('preproc', preprocessor),\n",
    "    ('clf', logreg_clf)\n",
    "])\n",
    "\n",
    "pipe_tree = SKPipeline(steps=[\n",
    "    ('preproc', preprocessor),\n",
    "    ('clf', tree_clf)\n",
    "])\n",
    "\n",
    "pipe_rf = SKPipeline(steps=[\n",
    "    ('preproc', preprocessor),\n",
    "    ('clf', rf_clf)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae3a243",
   "metadata": {},
   "source": [
    "# Definici√≥n de espacio para hiperpar√°metros para para GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b60ac3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_logreg = {\n",
    "    'clf__C': [0.01, 0.1, 1, 10],\n",
    "    'clf__solver': ['lbfgs', 'liblinear'],\n",
    "    'clf__penalty': ['l2']  \n",
    "}\n",
    "\n",
    "param_grid_tree = {\n",
    "    'clf__max_depth': [3, 5, 7, 9, None],\n",
    "    'clf__min_samples_split': [2, 10, 20],\n",
    "    'clf__min_samples_leaf': [1, 5, 10]\n",
    "}\n",
    "\n",
    "param_grid_rf = {\n",
    "    'clf__n_estimators': [100, 200],\n",
    "    'clf__max_depth': [5, 10, None],\n",
    "    'clf__min_samples_split': [2, 10],\n",
    "    'clf__min_samples_leaf': [1, 5],\n",
    "    'clf__max_features': ['sqrt', 'log2']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcad348",
   "metadata": {},
   "source": [
    "# Configuraci√≥n de validaci√≥n cruzada estratificada y m√©trica prioritaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a82ac9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer_recall_pos = make_scorer(recall_score, pos_label=1)\n",
    "\n",
    "cv = StratifiedKFold(\n",
    "    n_splits=5,\n",
    "    shuffle=True,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c426c37",
   "metadata": {},
   "source": [
    "# Lanzamiento de GridSearchCV para cada modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44f6fe17",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'logreg': (pipe_logreg, param_grid_logreg),\n",
    "    'tree': (pipe_tree, param_grid_tree),\n",
    "    'rf': (pipe_rf, param_grid_rf)\n",
    "}\n",
    "\n",
    "grid_results = {}\n",
    "best_estimators = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879b0b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Entrenando y buscando hiperpar√°metros para: logreg\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Mejor recall (CV) para logreg: 0.8769\n",
      "Mejores hiperpar√°metros: {'clf__C': 1, 'clf__penalty': 'l2', 'clf__solver': 'lbfgs'}\n",
      "\n",
      "üîπ Entrenando y buscando hiperpar√°metros para: tree\n",
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n",
      "Mejor recall (CV) para tree: 0.8957\n",
      "Mejores hiperpar√°metros: {'clf__max_depth': None, 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 2}\n",
      "\n",
      "üîπ Entrenando y buscando hiperpar√°metros para: rf\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "Mejor recall (CV) para rf: 0.8703\n",
      "Mejores hiperpar√°metros: {'clf__max_depth': None, 'clf__max_features': 'log2', 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 2, 'clf__n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "for name, (pipe, param_grid) in models.items():\n",
    "    print(f\"\\nüîπ Entrenando y buscando hiperpar√°metros para: {name}\")\n",
    "    \n",
    "    gs = GridSearchCV(\n",
    "        estimator=pipe,\n",
    "        param_grid=param_grid,\n",
    "        scoring=scorer_recall_pos,   \n",
    "        cv=cv,\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    gs.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"Mejor recall (CV) para {name}: {gs.best_score_:.4f}\")\n",
    "    print(\"Mejores hiperpar√°metros:\", gs.best_params_)\n",
    "    \n",
    "    grid_results[name] = gs\n",
    "    best_estimators[name] = gs.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81917b97",
   "metadata": {},
   "source": [
    "# Resumen de recall e hiperpar√°metros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7447403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelo</th>\n",
       "      <th>mejor_recall_CV</th>\n",
       "      <th>mejores_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logreg</td>\n",
       "      <td>0.876870</td>\n",
       "      <td>{'clf__C': 1, 'clf__penalty': 'l2', 'clf__solv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tree</td>\n",
       "      <td>0.895725</td>\n",
       "      <td>{'clf__max_depth': None, 'clf__min_samples_lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.870328</td>\n",
       "      <td>{'clf__max_depth': None, 'clf__max_features': ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   modelo  mejor_recall_CV                                     mejores_params\n",
       "0  logreg         0.876870  {'clf__C': 1, 'clf__penalty': 'l2', 'clf__solv...\n",
       "1    tree         0.895725  {'clf__max_depth': None, 'clf__min_samples_lea...\n",
       "2      rf         0.870328  {'clf__max_depth': None, 'clf__max_features': ..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resumen_modelos = []\n",
    "\n",
    "for name, gs in grid_results.items():\n",
    "    resumen_modelos.append({\n",
    "        'modelo': name,\n",
    "        'mejor_recall_CV': gs.best_score_,\n",
    "        'mejores_params': gs.best_params_\n",
    "    })\n",
    "\n",
    "resumen_df = pd.DataFrame(resumen_modelos)\n",
    "resumen_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8a5c5b",
   "metadata": {},
   "source": [
    "**Nota:** durante el proceso de modelado se entrenaron y compararon tres clasificadores distintos (regresi√≥n log√≠stica, √°rbol y random forest) utilizando validaci√≥n cruzada estratificada y b√∫squeda de hiperpar√°metros mediante GridSearchCV. Para cada modelo se evalu√≥ el desempe√±o en t√©rminos de recall, dado que esta m√©trica es prioritaria en un contexto donde es m√°s costoso no identificar correctamente a los casos positivos.\n",
    "\n",
    "En el caso de la regresi√≥n log√≠stica, se analizaron ocho combinaciones de hiperpar√°metros a lo largo de cinco particiones de validaci√≥n cruzada, para un total de 40 modelos entrenados. El mejor desempe√±o alcanz√≥ un recall promedio de 0.8769, con una configuraci√≥n √≥ptima que incluye un valor de regularizaci√≥n C = 1, penalizaci√≥n L2 y el solver lbfgs.\n",
    "\n",
    "Para el √°rbol, la b√∫squeda fue m√°s amplia, evaluando 45 combinaciones de par√°metros y entrenando 225 modelos en total. Este clasificador obtuvo un recall promedio superior al de la regresi√≥n log√≠stica, alcanzando 0.8957. Los mejores hiperpar√°metros corresponden a un √°rbol sin l√≠mite de profundidad, con una m√≠nima restricci√≥n en el n√∫mero de muestras requeridas para dividir nodos o formar hojas.\n",
    "\n",
    "En el caso del random forest, se evaluaron 48 configuraciones distintas, lo que implic√≥ entrenar 240 modelos. Su mejor recall promedio fue de 0.8703, un valor menor al de los otros dos clasificadores. Los hiperpar√°metros √≥ptimos incluyen un n√∫mero moderado de 100 √°rboles, profundidad ilimitada, uso del criterio ‚Äúlog2‚Äù para seleccionar caracter√≠sticas en cada divisi√≥n y par√°metros m√≠nimos bajos para dividir nodos y formar hojas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da24ab55",
   "metadata": {},
   "source": [
    "# Almacenamiento de los tres modelos de forma independiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d94025e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado: ../models/modelo_logreg.joblib\n",
      "Modelo guardado: ../models/modelo_tree.joblib\n",
      "Modelo guardado: ../models/modelo_rf.joblib\n"
     ]
    }
   ],
   "source": [
    "os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "for name, model in best_estimators.items():\n",
    "    ruta = f\"../models/modelo_{name}.joblib\"\n",
    "    joblib.dump(model, ruta)\n",
    "    print(f\"Modelo guardado: {ruta}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44511925",
   "metadata": {},
   "source": [
    "# Comparaci√≥n r√°pida de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66596537",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar_modelo(nombre, modelo, X_test, y_test):\n",
    "    y_pred = modelo.predict(X_test)\n",
    "    y_proba = modelo.predict_proba(X_test)[:, 1] if hasattr(modelo, \"predict_proba\") else None\n",
    "    \n",
    "    print(f\"\\n===== {nombre} =====\")\n",
    "    print(\"Reporte de clasificaci√≥n:\")\n",
    "    print(classification_report(y_test, y_pred, digits=4))\n",
    "    \n",
    "    if y_proba is not None:\n",
    "        print(\"ROC AUC:\", roc_auc_score(y_test, y_proba))\n",
    "    \n",
    "    print(\"Matriz de confusi√≥n:\")\n",
    "    print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "847f74f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== logreg =====\n",
      "Reporte de clasificaci√≥n:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8308    0.9025    0.8652      8000\n",
      "           1     0.9310    0.8775    0.9035     12000\n",
      "\n",
      "    accuracy                         0.8875     20000\n",
      "   macro avg     0.8809    0.8900    0.8843     20000\n",
      "weighted avg     0.8910    0.8875    0.8882     20000\n",
      "\n",
      "ROC AUC: 0.9339465729166667\n",
      "Matriz de confusi√≥n:\n",
      "[[ 7220   780]\n",
      " [ 1470 10530]]\n",
      "\n",
      "===== tree =====\n",
      "Reporte de clasificaci√≥n:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8368    0.8113    0.8238      8000\n",
      "           1     0.8767    0.8945    0.8855     12000\n",
      "\n",
      "    accuracy                         0.8612     20000\n",
      "   macro avg     0.8567    0.8529    0.8547     20000\n",
      "weighted avg     0.8607    0.8612    0.8608     20000\n",
      "\n",
      "ROC AUC: 0.8528749999999999\n",
      "Matriz de confusi√≥n:\n",
      "[[ 6490  1510]\n",
      " [ 1266 10734]]\n",
      "\n",
      "===== rf =====\n",
      "Reporte de clasificaci√≥n:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8338    0.9968    0.9080      8000\n",
      "           1     0.9975    0.8675    0.9280     12000\n",
      "\n",
      "    accuracy                         0.9192     20000\n",
      "   macro avg     0.9156    0.9321    0.9180     20000\n",
      "weighted avg     0.9320    0.9192    0.9200     20000\n",
      "\n",
      "ROC AUC: 0.9419305052083333\n",
      "Matriz de confusi√≥n:\n",
      "[[ 7974    26]\n",
      " [ 1590 10410]]\n"
     ]
    }
   ],
   "source": [
    "for name, best_model in best_estimators.items():\n",
    "    evaluar_modelo(name, best_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2596fb90",
   "metadata": {},
   "source": [
    "**Nota:** La comparaci√≥n de modelos muestra que la regresi√≥n log√≠stica ofrece un desempe√±o s√≥lido y equilibrado, con un accuracy de 0.8875 y un AUC de 0.93. Detecta correctamente la mayor parte de los casos, alcanzando un recall de 0.88 para la clase positiva y una precisi√≥n de 0.93, aunque a√∫n presenta un n√∫mero moderado de falsos negativos (1470). \n",
    "\n",
    "El √°rbol, en contraste, obtiene un rendimiento inferior, con un accuracy de 0.8612 y un AUC de 0.85. Aunque logra una buena sensibilidad para la clase positiva (recall de 0.89), presenta m√°s errores globales, especialmente un mayor n√∫mero de falsos positivos y falsos negativos, lo que limita su capacidad de generalizaci√≥n.\n",
    "\n",
    "El random forest resulta ser el modelo m√°s robusto y preciso. Con un accuracy de 0.9192 y un AUC de 0.94, supera claramente a los otros modelos. Su desempe√±o destaca por su capacidad para evitar falsos positivos (solo 26) y por mantener una precisi√≥n muy alta en ambas clases (superior al 0.99). Aunque su recall para la clase positiva es ligeramente menor que el de la regresi√≥n log√≠stica (0.8675), su equilibrio general entre precisi√≥n, sensibilidad y discriminaci√≥n lo convierte en el mejor modelo por ahora. \n",
    "\n",
    "No obstante, es necesario evaluar la curva de aprendizaje de todos los modelos para verificar s√≠ hay o no sobreajuste. Esto se despliega en el cuadernillo 04_Evaluaci√≥n y comunicaci√≥n. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
